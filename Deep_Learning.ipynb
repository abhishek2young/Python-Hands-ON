{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Objective Of Deep Learning\n",
    "* To build an AI system capable enough to predict and to take decision on behalf of Human being.\n",
    "\n",
    "> Disadvantage of Machine Learning \n",
    "* We are able to build model only on structured data in machine learning.\n",
    "\n",
    "> Deep learning is applicable for Unstructured data.\n",
    "> Types of Unstructured data \n",
    "1. Text   > Recurrent Neural Network \n",
    "2. Images \n",
    "3. Audio\n",
    "4. Video\n",
    "\n",
    "> Text\n",
    "* Example if we have 200 to 300 sentences and suppose we have 10,000 words each word will act as Individual Features and because of which our dimensionality of dataset gets increased (In Naive Bayes and SVM we can handle features upto 2000 and not beyond it will not work correctly)\n",
    "\n",
    "> Image \n",
    "* In Case of Image (Image is created by multiple pixels)\n",
    "* Resolution > Count of Pixels    >> Examples >> HD , Ultra HD\n",
    "* 14 inch Laptop >> Resolution >> 1920 * 1080 >> 20,73,500 Pixels on my laptop.\n",
    "* In Image data each pixel act as individual feature.\n",
    "* In such cases Machine learning models will not work correctly for such amount of features and becuase of which we use Deep Learning In Such Cases.\n",
    "\n",
    "\n",
    "> Performance graph betwenn ML and DL \n",
    "* DL can handle more complex data then ML and thats why DL came in use.\n",
    "* Ml is Suitable for simple data and DL is more suitable for complex data.\n",
    "* Complex data is that in the data we have curse of dimensionality (High Dimensional Data) and number of records is also High (Number of rows)\n",
    "\n",
    "> Use of Unstructured data \n",
    "1. Text data (NLP >> RNN , LSTM(Big brother of RNN)) >> In case of chatgpt we give text data input and the output we get from it is also in text format in its own language, >> Language Translation \n",
    "2. Image data (CNN,ANN) >> AI Image, >> lenskart (Choosing frames option)\n",
    "3. Audio data (Audio Analytics) >> Voice Cloning , >> Audio data of customers can be used by Industry to see if the customer is happy or not while talking to Customer Service.\n",
    "4. Video Analytics >> We know our universe is continuously expanding so to calculate the distance of the objects captured NASA uses Video Analytics to calculate distance between the objects, >> In terms of Crash test for safety ratings previously multiple crash test were done to calculate the safety of the car by use of video analytics we can reduce the number of crashes and instead study the safety of the car by a single video.\n",
    "* In Video Analytics we convert video to image \n",
    "\n",
    ">CPU (Central Processing Unit):\n",
    "* General-purpose processor for a wide range of tasks.\n",
    "* Few powerful cores optimized for sequential processing.\n",
    "* Suited for complex decision-making and control flow.\n",
    "\n",
    ">GPU (Graphics Processing Unit):\n",
    "* Originally designed for graphics rendering and parallel processing.\n",
    "* Many small, specialized cores for parallel tasks.\n",
    "* Suited for parallelizable tasks like graphics, machine learning, and simulations.\n",
    "\n",
    "> Cardinality \n",
    "* If we have categorical data in target columns we need to do label encoding.\n",
    "* Label encoding is done when we have order in our categorical data.In case of label encoding if we have more values then the model can give higher weightage for maximum values.(We have 3 to 4 categorical data)\n",
    "* In One hot encoding we will get more features and there will be curse of Dimensionality which is not Good.\n",
    "* Having many categorical values in our features is called as Cardinality.\n",
    "* In such cases we use one technique by deciding the weight of the each category and the error associated with that category in the total feature, in this way we select only category which has high presence and low error.\n",
    "* cardinality affects vertically in the dataset (In terms of rows)\n",
    "\n",
    "> Curse of Dimensionality\n",
    "* Higher number of Independent features causes Curse of Dimensionality.\n",
    "* It affects the data Horizontally.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Perceptron > Before Deep Learning we used this Algorithm.\n",
    "* It is a 2 Stage Algorithm.\n",
    "* It is a part of Machine Learning.\n",
    "* Weight,Bias >> External parameters\n",
    "* Suppose we have X1,X2,X3 and X4 as input parameters and we have W1,W2,W3,W4 as weights for each parameter.\n",
    "* And we get Yp as Output Parameter.\n",
    "> Stage 1 (Summation function) Z\n",
    "* As it is a 2 stage algorithm in first stage we will perform summation (Z) \n",
    "* Z = Sumation (Wi * Xi + b)   \n",
    "* b >> Bias \n",
    "> Stage 2 (Activation function) Sigmoid\n",
    "* Sigmoid(Z) = 1 / (1 + e^-Z)\n",
    "* Y(Predicted) will be the output of Sigmoid Function.\n",
    "* This whole process is known as Perceptron and Perceptron itself act as a Neuron in Neural Network.\n",
    "\n",
    "* Perceptron was used for creating Neural Network and that perceptron is calleds as Neuron.\n",
    "* Neural Network is made up of n numbers of different algorithms.\n",
    "* Hence Neural Network is called a Architecture and not a Algorithm.(ANN , CNN)\n",
    "\n",
    "> What is Sigmoid ?\n",
    "* It is used to add Non Linearity \n",
    "* Sigmoid converts continous values into probability distribution.(Range 0 to 1)\n",
    "* It always give probalistic value.\n",
    "* It always gives probablity value of any one class.\n",
    "\n",
    "> Structure of Neural Network\n",
    "* Network >> When there is a connection between Source and Sink.\n",
    "* When there is a connection between Neuron1 and Neuron2 then there is Neural Network.\n",
    "* When Neuron1 and Neuron2 are connected then there is Neural Network.For connection between the Neurons Some weight is assigned to this Connection.\n",
    "* Bias in this term is different from Machine Learning.\n",
    "* We will apply Bias to the Head of the Neurons.\n",
    "* Input Layer >> It hold the input and feed them to hidden layer.\n",
    "* There is only one input layer\n",
    "* Hidden layer >> Done all the processing / Learning \n",
    "* Hidden layer can be one or more than one.\n",
    "* If there is only one Hidden layer then it is called as Shalow Neural Network.\n",
    "* If there is more than 1 Hidden layer then it is called as Deep Neural Network.\n",
    "* We have our Learning only in our hidden layer.\n",
    "* Output Layer >> It shows Output.\n",
    "* Output layer is always one layer.\n",
    "\n",
    "> How data flow in neural networks?\n",
    "* Number of neuron in Input Layer = Number of input features\n",
    "* Number of Neuron in Output Layer = Decided by the activation function and number of event\n",
    "\n",
    "> Case 1 Lets say we are dealing with binary classification and in our output layer we have Sigmoid activation function.\n",
    "* How many neurons will be there in the output layer ?\n",
    "> 1\n",
    "\n",
    "> Case 2 Lets say we are dealing with Multiclass classification and in our output layer we have SoftMax as a activation function (Softmax activation is used for Multiclass classification and is the modified version of Sigmoid activation) and number of event is 5\n",
    "* No of neurons will be there in the output layer ?\n",
    "> 5\n",
    "\n",
    "> Case 3 Lets say we are dealing with regression problems and in our output layer we have relu as a activation function (Relu activation is used for regression) \n",
    "* No of neurons will be there in the output layer ?\n",
    "> 1 (Continous Value)\n",
    "\n",
    "* We have 7 to 8 activation functions \n",
    "* Number of neurons in the output layer will depend on the activation function.\n",
    "\n",
    "> Number of Neurons in the Hidden layer?\n",
    "* Not fixed \n",
    "\n",
    "> General thumb rule (Manually building ANN)\n",
    "* If we have 15 neurons as input layer and we are getting 3 neurons in the output layer so naturally the neurons in the hidden layer will be in the range (3 to 15).\n",
    "* If we increase the number of neurons (Neuron is itself a algoritm) our complexity of the architecture(Neural Network) will increase and our Computation cost and time will increase and more resources will be Used.\n",
    "\n",
    "> Shape of the Layers \n",
    "* If we have 3 neurons in 1 Container as our input layer then we say the shape of the Input Layer is = (1,3)\n",
    "* Likewise we have shape of the hidden layer 1 as (1,4) and shape of the hidden layer 2 as (1,2) and shape of the output layer is (1,1).\n",
    "\n",
    "> How to control shape of the Layers in Neural Network?\n",
    "* Lets Consider W1 (Weight Matrix) and we start from 3 Neurons and we end with 4 Neurons\n",
    "* We will get 12 connections and we will get weight for each connection that is we will get 12 weights.\n",
    "* So the shape of W1 will be (4,3)\n",
    "* Sumation (Z) = summation (Wi * Xi + b)\n",
    "* Sumation (Z) = summation (Wi^T * Xi + b) >> T = Transpose\n",
    "\n",
    "* Weight decide the shape of the Layers.\n",
    "\n",
    "> Importance of Bias?\n",
    "* Bias is a 1 dimensional array that consists values of Bias.\n",
    "> Z = summation (Wi * Xi + b)\n",
    "* Even if we have 0 as the value of Independent variable while calculating Z we shouls not get the output of that variable as Zero we add Bias.Or we can also say that to add importance to that feature we add Bias.\n",
    "\n",
    "> How Neural Network learns?\n",
    "* We follow a chain rule for selecting optimal weight and bias which are external parameters.\n",
    "* Same steps we followed in Gradient Descent in Linear regression for finding optimal m and c values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Comparison of Linear regression and ANN \n",
    "* Formula for Y in linear regression is Y = MX + C  and formula for Z in ANN is Z = Summation(Wi * Xi + b)\n",
    "* We find out best values of m and c in linear regression and in ANN we find the best values of W and b.\n",
    "* We use Gradient Descent algorithm for both linear regression and ANN.\n",
    "* In linear regression Mnew = Mold - alpha * (Daeba[L] / (Daeba[M]))\n",
    "*                      Cnew = Cold - alpha * (Daeba[L] / (Daeba[C]))\n",
    "* In ANN               Wnew = Wold - alpha * (Daeba[L] / (Daeba[W]))\n",
    "                       bnew = bold - alpha * (Daeba[L] / (Daeba[b]))\n",
    "\n",
    "* In above formula for ANN we saw (Daeba[L] / (Daeba[W])) these are gradient.\n",
    "* Gradient tells us that Change in Loss with respect to Weight.\n",
    "* In ANN we calculate multiple loss to find the minimum loss amongst all losses.\n",
    "* By finding the minimum loss we will find the best values of W and b.\n",
    "* By finding the Best values of W and b we will find the Best Sumamation function.\n",
    "* Then we will select the activation function.\n",
    "* Finally we will get the Y predicted.\n",
    "* The above process can also be called as Learning.\n",
    "* \n",
    "> Start of Lec \n",
    "* When we follow the process from input layer to hidden layers and then to Output layer this process is called as Forward Propogation.\n",
    "* When we go from hidden layer 2 to hidden layer1 to calculate the best values of W and b this process is called as Backward Propogation.\n",
    "* \n",
    "> Forward Propogation\n",
    "* Work of forward propagation is to calculate the Y predicted and Loss.\n",
    "* \n",
    "> Backward Propogation\n",
    "* Work of backward propagation is to update the Weight and bias.\n",
    "* \n",
    "> Epoch / Iteration\n",
    "> Case 1\n",
    "* Lets say we have 1500 data points \n",
    "* If we are applying forward propagation and backward propagation on these 1500 data points then we will perform 1 Epoch.\n",
    "* We can control the number of Epoch to control the complexity of the Architecture.\n",
    "* \n",
    "> Case 2\n",
    "* Suppose we divide the 1500 data points in 3 Batches of 500.\n",
    "* And we apply Forward propagation and backward propagation on each batch Simultaneously .\n",
    "* Each Forward Propogation and Backward Propogation on a batch is called as Iteration.\n",
    "* And combination of 3 Iterations creates 1 Epoch.\n",
    "* we are performing the above process in 3 batches Simultaneously.\n",
    "* \n",
    "> In Case 1 our resource consumption will be High but in Case 2 we are dividing the data and then performing iterations this process in Case 2 is called as Parallel and Distribution Learning.\n",
    "* In Parallel and Distribution Learning we are working simultaneously on 3 Batches(Case 2) so it called as Parallel and we are also dividing the data in 3 batches that is why it is called distribution and combining these we call it Parallel and Distribution Learning.\n",
    "* In Parallel and Distribution Learning our Burden of calculation will be reduced in short our time complexity will be reduced and also the consumption of resources will be reduced.\n",
    "> Example of Parallel and Distribution Learning is picking a sand of Bag by one hand and picking the same sand Bag by both hands.Our efforts will be reduced when we pick the sand Bag by both hands.Efforts in this case can be related by the Resouces used while building our architecture.\n",
    "* \n",
    "> Simple Example of how Neural Network works \n",
    "* Suppose when we consider about trying to do savings , we will consider different types of expenses like shopping expenses, food expenses , Travel expenses , Entertainment expenses and so on.Now I will try to give weightage on each type of expense while spending. Like my weightage for Entertainment expenses will be high as compared to Food expenses.Then i will decide about my weightage of each type of expense at every month ending for the next month, this is called as Learning. Weightage is important while considering Learning.\n",
    "*   \n",
    "> Types of Functions used in Neural Network\n",
    "* \n",
    "1. Optimization Function ( Same as Gradient Descent Algorithm) \n",
    "* To Minimize or optimize the error.\n",
    "* It is used to find best value for Weight and bias.\n",
    "* It helps to achieve Convergence(To Obtain Global minima).\n",
    "* \n",
    "2. Activation Function \n",
    "* Governing the way of Neuron Behave.\n",
    "* It controls the output of any Neuron.\n",
    "* \n",
    "3. Loss Function \n",
    "* It gives a number which represent the goodness of Model.\n",
    "* It helps to Update the Neural Network parameter.\n",
    "* \n",
    "> 1. Optimization Function\n",
    "* Optimization of Loss function.\n",
    "* We can either minimize the value of the loss function or we can maximize the value of Gain function.\n",
    "* Example of Loss function >> Error\n",
    "* Example of Gain function >> Accuracy\n",
    "* We only use loss function in Neural Network.\n",
    "* \n",
    "> Types of Optimization Function\n",
    "* \n",
    "* In first type of Optimization function we dynamically update weight and bias.\n",
    "* Dynamically update >> Continuously update\n",
    "* \n",
    "* In Second type of Optimization function we dynamically update learning rate \n",
    "* \n",
    "* In third type of Optimization function we dynamically update learning rate, Weight and bias.\n",
    "* \n",
    "> 1. Gradient Descent Algorithm (In ANN we call it as Batch Gradient Descent(Batch >> Complete Data) Algorithm)(BGDA)\n",
    "* In BGDA epoch get perform on whole data no matter how big our dataset.\n",
    "> Lets say we 1000 data points and we apply BGDDA on that data and we achieve Convergence in 1 minute and memory consumption will be 1GB  \n",
    "* For 1,00,000 data points we will require 100 min and 100GB consumption which is not Good.\n",
    "* \n",
    "> Drawbacks of BGDA \n",
    "* We cannot use BGDA in case of Big data because Epoch get performed on whole data.\n",
    "* \n",
    "> How BGDA works in Backend?\n",
    "* Suppose we have 1000 data points in dataset having 1 independent and 1 dependent variable.\n",
    "* And we perform BGDA on above dataset.\n",
    "* We will get Y predicted.\n",
    "* Now we have Y predicted and Y actual so we can calculate Loss(Error)\n",
    "* So now we can calculate Wnew and bnew.\n",
    "> Wnew = Wold - alpha * (Daeba[L] / Daeba[W])\n",
    "> bnew = bold + alpha * (Daeba[L] / Daeba[b])\n",
    "* \n",
    "> Advantages of BGDA \n",
    "* We get smooth learning curve(Parabola in GDA) beacuse we perform Epoch on whole data.\n",
    "* \n",
    "> In case of Gradient Descent our learning step reduces as we reach towards our Global Minima.\n",
    "* Because we have learned much from out previous learning step and we will not move aggressively towards the Global Minima as we did in our previous learning steps.\n",
    "* \n",
    "> 2. Stochastic Gradient Descent algorithm.(SGDA)\n",
    "* Stochastic >> Random or Randomness \n",
    "* Suppose we have 1000 data points and we will select one data point randomly from the data set.\n",
    "* We calculate Y predicted and Loss using Forward propagation(FP1) and backward propagation(BP1).\n",
    "* We can also call it as Iteration.\n",
    "* \n",
    "* In Stochastic Gradient Descent algorithm we consider single data point at a time randomly. \n",
    "* In SGDA 1 Epoch >> N number of Iteration  (N = Number of data points)\n",
    "* In SGDA we learn from single data point at a time hence learning curve becomes very noisy.\n",
    "> Example\n",
    "* Suppose we have [2,4,6,8,10,12,14,16,18,20] as data points.\n",
    "* 1st Iteration   > 6     > Yp1 , L1     > W` , b` \n",
    "* 2nd Iteration   > 12    > Yp2 , L2     > W`` , b``\n",
    "* 3rd Iteration   > 18    > Yp3 , L3     > W```, b```\n",
    "* We get our learning curve noisy that is we will have multiple local minima \n",
    "* In SDGA we can get stuck at Local minima instead of Global minima.\n",
    "* In SDGA since we are learning from single data point at a time we dont have sufficient amount of learning to overcome local minima point as a result after some time SDGA consider Local minima as a Global minima and that is wrong.\n",
    "> Advantage of SDGA \n",
    "* Compare to BDGA , SDGA require less resources to achieve Convergence.\n",
    "> Disadvantage of SDGA\n",
    "* It is vey prone to local minima because in SDGA we learn from single data point at a time hence we dont have sufficient amount of learning to overcome local minima.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 3.Mini Batch Stochastic Gradient Descent algorithm (MBSGDA) \n",
    "* We are creating mini batch randomly and applying Gradient Descent algorithm on it.\n",
    "* MBSGDA is a combination of BGDA or SGDA.\n",
    "* In BGDA we were getting smoothness of Curve and in SGDA we were doing step by step learning(Resources were used less and time was reduced).\n",
    "* Suppose we have a Batch(Complete data) and we are creating mini batches MB1, MB2 ,MB3 and MB4 by random sampling.\n",
    "* We will apply Forward propagation and backward propagation on each mini batch .\n",
    "* In forward propagation we will get Ypred and we will calculate the Loss.\n",
    "* For MB1 we will get Ypred1 and Loss L1 by forward propogation and we will apply backward propagation after that.\n",
    "* Same will apply for all mini batches.\n",
    "* We will calculate Loss of all mini batches and minimum of all losses will be selected (Min loss)\n",
    "* We will get the best values of Weight(W) and bias(b).\n",
    "* We will calculate the best Summation(Z) function.\n",
    "* Then we will aplly the Activation function.\n",
    "* And after that we will get Final Ypred.\n",
    "* We are performing parallel and distribution learning in MBSGDA.\n",
    "* Still we will get noise in our learning curve after performing above operations.\n",
    "* But our noise will be less as compared to SGDA.(Noise >> No Smoothness in Curve)\n",
    "* In MBGSDA we learn from mini batch at a time hence now we have sufficient amount of learning to overcome local minima point, we ensure that we will reach to Global minima.\n",
    "* \n",
    "> Advantages of MBSGDA\n",
    "*  Compared to BGDA ,MBSGDA requires less resources and time to achieve Convergence is less.\n",
    "* Since we are learning from mini batch at a time we have sufficient amount of learning to overcome local minima.\n",
    "* Hence we will reach to Global minima.\n",
    "* \n",
    "> Disadvantages of MBSGDA \n",
    "* Noise is still present in learning curve.\n",
    "* \n",
    "> why we dont want noise in our learning curve?\n",
    "* Example \n",
    "* Suppose we have 3 floor building and we want to hoist the flag on the building for Independence day.\n",
    "* And we are given ladder to climb on the building.\n",
    "* And we also have 2nd building  with 3 floors and with zig zag ladder.\n",
    "* We will require more time to climb the 2nd building as compared to the first building with strtaight ladder.\n",
    "* While comparing effort we will more effort on the first building as we have straihht ladder and we will require less effort on the second building as we have Zig zag ladder.\n",
    "* Now we also have 3rd building with 3 floors and with Spiral ladder.\n",
    "* Because of the Spiral ladder we will require less time and less effort for the 3rd building.\n",
    "* \n",
    "* Same applies for noise , if we remove noise we will require less time and less resources to achieve the Convergence.\n",
    "* By reducing the noise we can overcome the disadvantage of MBSGDA.\n",
    "*   \n",
    "> Random Sampling \n",
    "* Suppose we have 1000 data points and we create 4 mini batches each containing 250 data points.\n",
    "* In Random Sampling while choosing the samples for mini batches we ensure the distribution remains identical as the original dataset.\n",
    "* \n",
    "> 4. Mini batch stochastic gradient descent algorithm with momentum.\n",
    "* Momentum >> Smoothning of the learning curve(Removing Noise).\n",
    "> Working \n",
    "* Formula \n",
    "> Wnew = Wold - alpha * (Daeba[L] / Daeba[W])\n",
    "> bnew = bold - alpha * (Daeba[L] / Daeba[b])\n",
    "* We will apply momentum to our Gradients (Daeba[L] / Daeba[W]) and (Daeba[L] / Daeba[b]).\n",
    "* Gradient >> Potential Energy \n",
    "* At the start of the learning curve the starting point will have maximum gradient(Changes in Loss with respect to Weight)as the point which will be closer to the Global minima.\n",
    "* Updated equations \n",
    "> Wnew = Wold - alpha * Vdw\n",
    "> bnew = bold - alpha * Vdb\n",
    "* Vdw, Vdb = Velocity Components\n",
    "> Vdwt = Beta * Vdw t-1 + (1 - beta) (Daeba[L] / Daeba[W])\n",
    "> Vdbt = Beta * Vdb t-1 + (1 - beta) (Daeba[L] / Daeba[b])\n",
    "* where t = no of hidden layer\n",
    "* Beta >> Smoothning parameter(Range 0 to 1)\n",
    "* Vdw , Vdb >> Velocity Components\n",
    "> Case 1 Beta =0 \n",
    "* Vdwt = (Daeba[L] / Daeba[W])  >>> No Smoothning\n",
    "> Case 2 Beta = 1 \n",
    "* Vdwt = Vdw t-1                >>> Full Smoothning \n",
    "> Case 3 Beta = 0.98\n",
    "* Vdwt = Beta * Vdw t-1 + (1 - beta)  (Daeba[L] / Daeba[W])\n",
    "* In above formula (Beta * Vdw t-1) represents Magnitude and (1 - beta) (Daeba[L] / Daeba[W]) represents direction.\n",
    "* \n",
    "> Above revision \n",
    "1. By Gradient descent algorithm we were getting a smooth learning curve with no noise but the problem we were facing that the gradient descent algorithm took more time and used more resources which is Bad.So people workin on it thought we should create another algorithm.\n",
    "2. Then Came the Stochastic Gradient Descent algorithm here we were selecting a random data point and performing the forward propagation and backward propagation on a single data point.In Stochastic Gradient Descent algorithm we had reduced out time complexity and also reduced the usage of resources, but the problem we were facing that as we had no previous learning experience were not able to overcome the local minima and so our local minima was consirded as the global minima which is bad.\n",
    "3. To overcome this issue then came Mini Batch Stochastic Gradient Descent algorithm in this algorithm we were creating mini batches of data points and then performing the forward propagation and backward propagation on each mini batch of data points simultaneously.In Mini Batch Stochastic Gradient Descent algorithm we use parallel and distribution learning.In this algorithm we had enough data points to have the learning experience to overcome the local minima and so our algorithm was good enough then SGDA.\n",
    "4. But we were still facing the noise issue in our learning curve , noise present in our learning curve says that we are using more resources and more time is being spent.To solve this issue came Mini Batch Stochastic Gradient Descent algorithm with momentum.Momentum is smoothning of the learning curve.We are applying momentum on our Gradients.We are replacing gradients by velocity components.Why we are applying Momentum only on Gradients? lets consider Gradients as Potential energy.When we use equations(Wnew = Wold - alpha * (Daeba[L] / (Daeba[W]))) we get noise in our learning curve.To avoid this noise we need to control the gradients and so we will replace the gradients with velocity components.So the updated equations are \n",
    "> Vdwt = Beta * Vdw t-1 + (1 - beta) (Daeba[L] / Daeba[W])\n",
    "> Vdbt = Beta * Vdb t-1 + (1 - beta) (Daeba[L] / Daeba[b])\n",
    "* where t = no of hidden layer\n",
    "* Beta >> Smoothning parameter(Range 0 to 1)\n",
    "* Vdw , Vdb >> Velocity Components\n",
    "> Case 1 Beta =0 \n",
    "* Vdwt = (Daeba[L] / Daeba[W])  >>> No Smoothning\n",
    "> Case 2 Beta = 1 \n",
    "* Vdwt = Vdw t-1                >>> Full Smoothning \n",
    "> Case 3 Beta = 0.98\n",
    "* Vdwt = Beta * Vdw t-1 + (1 - beta)  (Daeba[L] / Daeba[W])\n",
    "* In above formula (Beta * Vdw t-1) represents Magnitude and (1 - beta) (Daeba[L] / Daeba[W]) represents direction.\n",
    "* With help of Beta we can control the gradients and by that we control the Noise in the learning curve.\n",
    "* \n",
    "> Best optimization function for Weight and bias ?\n",
    "* MIni Batch Stochastic Gradient descent algorithm with momentum.(MBSGDA with momentum)\n",
    "* \n",
    "> Why we need to update learning rate dynamically in Neural Network?\n",
    "* Before studying about Learning Rate we need to understand Learning Step.\n",
    "* When we start a point on learning curve whatever baby steps we take to reach towards our Global minima are called as learning steps.\n",
    "* The rate through which our learning steps vary are called as learning rate.\n",
    "> Difference between Machine Learning and Deep Learning?\n",
    "* In Machine Learning when we build a model before that we make changes in our data by the host . We create a dataset which is suitable for our model.we check Distribution of the data , Multicolinearity reduce, Feature selection techniques apply it means we remove our anomaly.\n",
    "* In Machine Learning there is less complexity that is why if we keep learning rate high then also it doesnot affect much it doesnot apply on Deep Learning.\n",
    "* Because in Deep Learning we neither apply feature selection techniques , nor Feature Engineering because the Deep Learning(ANN) architecture itself selects the features which have weightage or have importance.\n",
    "* As we are not making any changes in the data the complexity of the data is high so we need to dynamically update the learning rate is mandatory.\n",
    "* \n",
    "> Case 1 If learning rate is too small then what will happen?\n",
    "* If we are having small learning rate then our learning steps would be too small we will not be able to reach to the Global minima then this phenomenon is called as Vanishing Gradient.\n",
    "* Training times increases exponentially.\n",
    "* We face Vanishing Gradient issue.\n",
    "* We never achive Convergence(Global minima)\n",
    "* \n",
    "> Case 2 If learning rate is too High then what will happen?\n",
    "* If we are having high learning rate then our learning steps would be too big it can overpass the global minima and this phenomenon is called called as Exploding Gradient.\n",
    "* We face over shooting issues .\n",
    "* Due to over shooting issues we face Exploding Gradient issue.\n",
    "> To avoid the vanishing gradient problem and Exploding Gradient issue we need to dynamically update the learning rate.\n",
    "> One more reason to dynamically update the learning rate is while considering the values to start with the learning rate we dont know the values we are considering for the learning rate may cause vanishing gradient issues or Exploding Gradient issues.While dynamically updating the learning rate we need not to worry about vanishing gradient issues or Exploding Gradient issues.\n",
    "* To dynamically update the learning rate we have 2 optimizations functions\n",
    "1. Ada Grad (Adaptive Gradient)\n",
    "* It learns from the gradient to update the learning rate.\n",
    "2. Ada Delta (RMS prop) >> Root mean squared propagation\n",
    "* \n",
    "> 1. Ada Grad (Adaptive Gradient)\n",
    "* Wnew = Wold - alpha(new) (Daeba[L] / Daeba[W])\n",
    "* bnew = bold - alpha(new) (Daeba[L] / Daeba[b])\n",
    "* alpha(new) = alpha(old) / sqrt[eta + E]    E = Epsilon\n",
    "* We use Epsilon to avoid zero division square eror\n",
    "* Where  eta = Summation (Daeba[L] / Daeba[W])^2 \n",
    "* We follow the weight gradient to update the learning rate.\n",
    "* This is called as Ada Grad (Adaptive Gradient)\n",
    "* If we increase the number of hidden layers our value of eta will also increase.\n",
    "* The value of ets is inversely proportional to the new learning rate.\n",
    "* If our value of eta is incresing then our value of new learning rate will decrease and we will face the Vanishing Gradient problem.\n",
    "> Draw back of Ada Grad (Adaptive Gradient)\n",
    "* We cannot use Ada Grad (Adaptive Gradient) in case of Deep Neural Network.\n",
    "* To overcome this problem we will see Ada Delta(RMS prop) >> Root Mean Squared Propagation.\n",
    "* \n",
    "> 2. Ada Delta(RMS prop) >> Root Mean Squared Propagation\n",
    "* We now replace eta by Sdwt\n",
    "* Now we have \n",
    "* Wnew = Wold - alpha(new) (Daeba[L] / Daeba[W])\n",
    "* bnew = bold - alpha(new) (Daeba[L] / Daeba[b])\n",
    "* alpha(new) = alpha(old) / sqrt[Sdwt + E] \n",
    "* Where Sdwt = velocity component\n",
    "* Vdwt = Beta * Vdw t-1  + (1 - beta) (Daeba[L] / Daeba[W])\n",
    "* Sdwt = Beta * Sdwt t-1 + (1 - beta) (Daeba[L] / Daeba[W])^2\n",
    "* Where Beta = Smoothning parameter\n",
    "* Sdwt doenot allow eta value to increase so our alpha value would not be reduced.\n",
    "* Sdwt caps the value of eta in a certain range it will decrease but it will not increase.\n",
    "* \n",
    "> Best optimization function for learning rate \n",
    "* Ada delta(RMS prop) >> Root Mean Squared propogation\n",
    "* \n",
    "> Best optimization function for Weight and bias?\n",
    "* Mini batch Stochastic Gradient Descent algorithm with momentum.\n",
    "> Best optimization function for learning rate ?\n",
    "* Ada delta(RMS prop) >> Root Mean Squared propogation\n",
    "* Applying two optimization functions seperately on algorithm can be time consuming and more resource intensive.\n",
    "* To overcome this we cobined the Mini batch Stochastic Gradient Descent algorithm with momentum and Ada delta(RMS prop) >> Root Mean Squared propogation and that optimization function is ADAM.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
